# Mistral CLI Test Suite

Umfassende Unit-Test-Suite fÃ¼r das mistralcli Python-Package.

## ğŸ“¦ Struktur

```
tests/
â”œâ”€â”€ conftest.py                      # Gemeinsame Fixtures & Setup
â”œâ”€â”€ pytest.ini                       # Pytest-Konfiguration (im Root)
â”‚
â”œâ”€â”€ core/                            # Core-Module Tests
â”‚   â”œâ”€â”€ test_config.py
â”‚   â”œâ”€â”€ test_logging_config.py
â”‚   â””â”€â”€ test_client.py
â”‚
â”œâ”€â”€ security/                        # Security-Module Tests
â”‚   â”œâ”€â”€ test_command_validator.py   # âœ… VollstÃ¤ndig (80+ Tests)
â”‚   â”œâ”€â”€ test_path_validator.py      # âœ… VollstÃ¤ndig
â”‚   â”œâ”€â”€ test_url_validator.py       # âœ… VollstÃ¤ndig (SSRF-Protection)
â”‚   â””â”€â”€ test_sanitizers.py          # âœ… VollstÃ¤ndig
â”‚
â”œâ”€â”€ auth/                            # Auth-Module Tests
â”‚   â””â”€â”€ test_api_key_manager.py
â”‚
â”œâ”€â”€ utils/                           # Utils-Module Tests
â”‚   â”œâ”€â”€ test_token_manager.py
â”‚   â”œâ”€â”€ test_formatting.py
â”‚   â””â”€â”€ test_helpers.py
â”‚
â””â”€â”€ tools/                           # Tools-Module Tests
    â”œâ”€â”€ test_definitions.py          # âœ… VollstÃ¤ndig (Tool-Schemas)
    â”œâ”€â”€ test_executor.py
    â”œâ”€â”€ test_system.py
    â”œâ”€â”€ test_filesystem.py           # âœ… VollstÃ¤ndig (5 Tools)
    â”œâ”€â”€ test_network.py
    â”œâ”€â”€ test_transfer.py
    â”œâ”€â”€ test_data.py
    â””â”€â”€ test_image.py
```

## ğŸš€ Installation

### 1. Test-Dependencies installieren

```bash
pip install -r requirements-test.txt
```

Oder einzeln:
```bash
pip install pytest pytest-cov pytest-mock pytest-benchmark
```

### 2. Projekt im Development-Modus installieren

```bash
pip install -e .
```

## ğŸ§ª Tests ausfÃ¼hren

### Alle Tests ausfÃ¼hren

```bash
pytest
```

### Mit Coverage-Report

```bash
pytest --cov=mistralcli --cov-report=html
```

Ã–ffne dann `htmlcov/index.html` im Browser fÃ¼r detaillierten Coverage-Report.

### Nur spezifische Module testen

```bash
# Nur Security-Tests
pytest tests/security/

# Nur einen spezifischen Test
pytest tests/security/test_command_validator.py

# Nur eine Test-Klasse
pytest tests/security/test_command_validator.py::TestDangerousCommands

# Nur eine spezifische Test-Funktion
pytest tests/security/test_command_validator.py::TestDangerousCommands::test_dangerous_rm_commands
```

### Mit Markern filtern

```bash
# Nur Unit-Tests (schnell)
pytest -m unit

# Nur Security-Tests
pytest -m security

# Nur langsame Tests
pytest -m slow

# Nur Tests die kein Netzwerk brauchen
pytest -m "not network"
```

### Verbose-Modus

```bash
pytest -v                    # Zeigt jeden Test
pytest -vv                   # Noch ausfÃ¼hrlicher
pytest -s                    # Zeigt print-Ausgaben
```

### Test-Output anpassen

```bash
pytest --tb=short            # Kurze Tracebacks
pytest --tb=line             # Eine Zeile pro Fehler
pytest -x                    # Stop bei erstem Fehler
pytest --maxfail=3           # Stop nach 3 Fehlern
```

## ğŸ“Š Coverage-Ziele

| Modul | Ziel | Status |
|-------|------|--------|
| **security/** | 95%+ | âœ… Tests komplett |
| **tools/** | 90%+ | ğŸ”„ In Arbeit |
| **core/** | 85%+ | â³ Ausstehend |
| **auth/** | 85%+ | â³ Ausstehend |
| **utils/** | 85%+ | â³ Ausstehend |
| **Gesamt** | 90%+ | ğŸ¯ Ziel |

## ğŸ·ï¸ VerfÃ¼gbare Test-Marker

Tests kÃ¶nnen mit Markern kategorisiert werden:

- `@pytest.mark.unit` - Schnelle Unit-Tests (Standard)
- `@pytest.mark.integration` - Integration-Tests (langsamer)
- `@pytest.mark.security` - Security-fokussierte Tests
- `@pytest.mark.slow` - Langsam laufende Tests
- `@pytest.mark.network` - Tests die Netzwerk benÃ¶tigen
- `@pytest.mark.requires_api_key` - Tests die Mistral API-Key benÃ¶tigen

## ğŸ› ï¸ Fixtures

Gemeinsame Fixtures in `conftest.py`:

### Verzeichnis-Fixtures
- `temp_dir` - TemporÃ¤res Verzeichnis
- `test_data_dir` - Test-Daten Verzeichnis

### Mock-Fixtures
- `mock_mistral_client` - Gemockter Mistral Client
- `mock_tool_call` - Gemockter Tool-Call
- `mock_requests_get` / `mock_requests_post` - Gemockte HTTP-Requests
- `mock_subprocess_run` - Gemockter subprocess
- `mock_keyring` - Gemocktes Keyring

### Datei-Fixtures
- `sample_text_file` - Beispiel-Textdatei
- `sample_json_file` - Beispiel-JSON-Datei
- `sample_csv_file` - Beispiel-CSV-Datei
- `sample_image_file` - Beispiel-Bilddatei (benÃ¶tigt PIL)

### Environment-Fixtures
- `clean_env` - Saubere Umgebung ohne API-Keys
- `mock_api_key` - Gesetzter Mock API-Key

### Security-Fixtures
- `dangerous_commands` - Liste gefÃ¤hrlicher Befehle
- `safe_commands` - Liste sicherer Befehle

## ğŸ“ Test schreiben

### Beispiel: Neuen Test hinzufÃ¼gen

```python
#!/usr/bin/env python3
"""
Unit Tests for mistralcli.module.feature

Description of what this module tests.
Version: 1.5.2
"""

import pytest
from mistralcli.module import feature_function


class TestFeature:
    """Tests for feature_function."""

    @pytest.mark.unit
    def test_basic_functionality(self):
        """Test basic functionality."""
        result = feature_function("input")
        assert result == "expected_output"

    @pytest.mark.unit
    @pytest.mark.security
    def test_security_validation(self):
        """Test security validation."""
        result = feature_function("malicious_input")
        assert result["success"] is False
        assert "error" in result

    @pytest.mark.unit
    def test_with_fixture(self, temp_dir):
        """Test using a fixture."""
        test_file = temp_dir / "test.txt"
        test_file.write_text("content")

        result = feature_function(str(test_file))
        assert result["success"] is True
```

### Parametrized Tests

```python
@pytest.mark.unit
@pytest.mark.parametrize("input,expected", [
    ("test1", "output1"),
    ("test2", "output2"),
    ("test3", "output3"),
])
def test_multiple_inputs(input, expected):
    """Test with multiple inputs."""
    result = feature_function(input)
    assert result == expected
```

## ğŸ› Debugging Tests

### Fehlgeschlagenen Test debuggen

```bash
# Zeige lokale Variablen bei Fehler
pytest -l

# Interaktiver Debugger bei Fehler
pytest --pdb

# Nur fehlgeschlagene Tests erneut ausfÃ¼hren
pytest --lf

# Nur letzte fehlgeschlagene + neue Tests
pytest --ff
```

### Performance-Profiling

```bash
# Zeige langsamste Tests
pytest --durations=10

# Mit Benchmark
pytest --benchmark-only
```

## ğŸ“ˆ CI/CD Integration

### GitHub Actions Beispiel

```yaml
name: Tests

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - uses: actions/setup-python@v2
        with:
          python-version: '3.10'
      - run: pip install -r requirements-test.txt
      - run: pytest --cov=mistralcli --cov-report=xml
      - uses: codecov/codecov-action@v2
```

## ğŸ”§ Konfiguration

### pytest.ini

Die Pytest-Konfiguration befindet sich in `pytest.ini` im Root-Verzeichnis.

Wichtige Einstellungen:
- Test Discovery: `test_*.py`, `Test*` Klassen
- Coverage: Automatisch aktiviert mit HTML/XML Reports
- Marker: Definiert fÃ¼r Kategorisierung
- Logging: Konfigurierbar via CLI

### Coverage-Konfiguration

Coverage-Einstellungen in `pytest.ini`:
- Source: `mistralcli`
- Omit: Tests selbst, `__pycache__`
- Reports: HTML, Terminal, XML

## ğŸ“š Best Practices

1. **Ein Test pro Assertion-Gruppe** - Tests sollten fokussiert sein
2. **Beschreibende Namen** - `test_feature_does_something_when_condition`
3. **AAA-Pattern** - Arrange, Act, Assert
4. **Fixtures verwenden** - Statt Wiederholung von Setup-Code
5. **Mocking fÃ¼r externe AbhÃ¤ngigkeiten** - Keine echten API-Calls
6. **Marker setzen** - FÃ¼r einfaches Filtern
7. **Parametrize fÃ¼r Ã¤hnliche Tests** - Reduziert Duplikation

## ğŸ¯ Status

**Aktueller Stand:**
- âœ… Test-Infrastruktur komplett
- âœ… Security-Tests komplett (80+ Tests)
- âœ… Tools-Definitions Tests komplett
- âœ… Filesystem-Tools Tests komplett
- ğŸ”„ Weitere Tools-Tests in Arbeit
- â³ Core-Module Tests ausstehend
- â³ Auth-Module Tests ausstehend
- â³ Utils-Module Tests ausstehend

**NÃ¤chste Schritte:**
1. Verbleibende Tools-Tests erstellen
2. Core-Module Tests erstellen
3. Auth-Module Tests erstellen
4. Utils-Module Tests erstellen
5. Integration-Tests hinzufÃ¼gen
6. CI/CD Pipeline einrichten

## ğŸ“§ Kontakt

Bei Fragen oder Problemen mit den Tests:
- Issue erstellen im GitHub-Repository
- Test-Dokumentation lesen in diesem README
